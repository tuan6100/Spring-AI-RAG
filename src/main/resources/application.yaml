
spring:
  application:
    name: ai-chat-bot

  main:
    allow-bean-definition-overriding: true

  threads:
    virtual:
      enabled: true

  servlet:
    multipart:
      max-file-size: 1GB
      max-request-size: 1GB

  ai:
    vectorstore:
      qdrant:
        host: localhost
        port: 6334
        collection-name: genshin_wiki
        vector-name: default

    ollama:
      base-url: http://localhost:11434
      init:
        pull-model-strategy: never
        chat:
          additional-models:
            - llama3.2
          include: true
        timeout: 120m
        max-retries: 10
      chat:
        options:
          temperature: 0.6
          top-k: 5
          top-p: 0.9
        model: llama3.2

  autoconfigure:
    exclude:
      - org.springframework.ai.vectorstore.qdrant.autoconfigure.QdrantVectorStoreAutoConfiguration
      - org.springframework.ai.model.transformers.autoconfigure.TransformersEmbeddingModelAutoConfiguration

  aop:
    auto: true
    proxy-target-class: tru

logging:
    level:
#      vn.edu.hust: DEBUG
      org:
        springframework:
          ai:
            chat:
              client:
                advisor: DEBUG
            vectorstore:
              qdrant: DEBUG

